# scripts/compare_models.py
"""
Fine-tuned KoELECTRA vs ì˜ì–´ GoEmotions ëª¨ë¸ ë¹„êµ
100ê°œ YouTube ëŒ“ê¸€ë¡œ ì„±ëŠ¥ ì¸¡ì •
"""
from __future__ import annotations

import os
import sys
import json
import time
from pathlib import Path
from collections import Counter
import asyncio

# í”„ë¡œì íŠ¸ ë£¨íŠ¸ ì¶”ê°€
PROJECT_ROOT = Path(__file__).parent.parent
sys.path.insert(0, str(PROJECT_ROOT))

import torch
import pandas as pd
from transformers import (
    ElectraTokenizer, 
    ElectraForSequenceClassification,
    AutoTokenizer,
    AutoModelForSequenceClassification,
    pipeline
)

# ============================================================
# 100ê°œ í…ŒìŠ¤íŠ¸ ëŒ“ê¸€
# ============================================================
from scripts.test_comments_100 import YOUTUBE_COMMENTS_100

# ============================================================
# ëª¨ë¸ 1: Fine-tuned KoELECTRA
# ============================================================
class KoELECTRAModel:
    def __init__(self):
        self.name = "Fine-tuned KoELECTRA"
        self.model_path = PROJECT_ROOT / "saved_models" / "ko-emotions_finetuned"
        self.threshold = 0.15
        
        print(f"\n{'='*70}")
        print(f"ğŸ“¦ {self.name} ë¡œë”© ì¤‘...")
        print(f"{'='*70}")
        
        # ë””ë°”ì´ìŠ¤ ì„¤ì •
        self.device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
        
        # ëª¨ë¸ ë¡œë“œ
        self.tokenizer = ElectraTokenizer.from_pretrained(self.model_path)
        self.model = ElectraForSequenceClassification.from_pretrained(self.model_path)
        self.model.to(self.device)
        self.model.eval()
        
        # ë©”íƒ€ë°ì´í„°
        self.id2label = self.model.config.id2label
        self.label2id = self.model.config.label2id
        self.num_labels = len(self.id2label)
        self.num_parameters = sum(p.numel() for p in self.model.parameters())
        
        # í•™ìŠµ ì •ë³´ ë¡œë“œ
        with open(self.model_path / "training_config.json", "r", encoding="utf-8") as f:
            self.training_info = json.load(f)
        
        print(f"âœ… ëª¨ë¸ ë¡œë“œ ì™„ë£Œ!")
        print(f"   - ê°ì • ë ˆì´ë¸”: {list(self.id2label.values())}")
        print(f"   - íŒŒë¼ë¯¸í„° ìˆ˜: {self.num_parameters:,}ê°œ")
        print(f"   - ë””ë°”ì´ìŠ¤: {self.device}")
    
    def predict(self, texts):
        """ëŒ“ê¸€ ë¦¬ìŠ¤íŠ¸ë¥¼ ì…ë ¥ë°›ì•„ ê°ì • ë¶„ì„"""
        results = []
        
        for text in texts:
            # í† í¬ë‚˜ì´ì§•
            inputs = self.tokenizer(
                text,
                max_length=128,
                padding='max_length',
                truncation=True,
                return_tensors='pt'
            )
            
            # GPUë¡œ ì´ë™
            inputs = {k: v.to(self.device) for k, v in inputs.items()}
            
            # ì˜ˆì¸¡
            with torch.no_grad():
                outputs = self.model(**inputs)
                logits = outputs.logits
                probs = torch.softmax(logits, dim=-1)[0]
                
                # ì£¼ìš” ê°ì •
                pred_id = torch.argmax(probs).item()
                pred_label = self.id2label[pred_id]
                pred_prob = probs[pred_id].item()
                
                # ì„ê³„ê°’ ì´ìƒ ê°ì • ì¶”ì¶œ
                detected_emotions = []
                for i, prob in enumerate(probs):
                    if prob.item() >= self.threshold:
                        emotion = self.id2label[i]
                        detected_emotions.append((emotion, prob.item()))
                
                detected_emotions.sort(key=lambda x: x[1], reverse=True)
                
                if not detected_emotions:
                    detected_emotions = [(pred_label, pred_prob)]
            
            results.append({
                'primary_emotion': pred_label,
                'confidence': pred_prob,
                'all_emotions': [e for e, p in detected_emotions],
                'all_scores': {e: p for e, p in detected_emotions}
            })
        
        return results


# ============================================================
# ëª¨ë¸ 2: ì˜ì–´ GoEmotions (ë²ˆì—­ í•„ìš”)
# ============================================================
class GoEmotionsModel:
    def __init__(self):
        self.name = "SamLowe/roberta-base-go_emotions"
        self.threshold = 0.15
        
        print(f"\n{'='*70}")
        print(f"ğŸ“¦ {self.name} ë¡œë”© ì¤‘...")
        print(f"{'='*70}")
        
        # ë””ë°”ì´ìŠ¤ ì„¤ì •
        self.device = 0 if torch.cuda.is_available() else -1
        
        # ëª¨ë¸ ë¡œë“œ
        self.tokenizer = AutoTokenizer.from_pretrained(self.name)
        self.model = AutoModelForSequenceClassification.from_pretrained(self.name)
        
        # íŒŒì´í”„ë¼ì¸ ìƒì„±
        self.pipe = pipeline(
            task="text-classification",
            model=self.model,
            tokenizer=self.tokenizer,
            device=self.device,
            top_k=None,  # ëª¨ë“  ê°ì • ë°˜í™˜
        )
        
        # ë©”íƒ€ë°ì´í„°
        self.num_labels = len(self.model.config.id2label)
        self.num_parameters = sum(p.numel() for p in self.model.parameters())
        
        # GoEmotions â†’ í”„ë¡œì íŠ¸ ê°ì • ë§¤í•‘
        self.label_map = {
            "admiration": "joy", "amusement": "joy", "approval": "joy",
            "excitement": "joy", "joy": "joy", "optimism": "joy",
            "pride": "joy", "relief": "joy",
            "caring": "love", "desire": "love", "love": "love",
            "gratitude": "gratitude",
            "anger": "anger", "annoyance": "anger",
            "disapproval": "anger", "disgust": "anger",
            "disappointment": "sadness", "embarrassment": "sadness",
            "grief": "sadness", "remorse": "sadness", "sadness": "sadness",
            "fear": "fear", "nervousness": "fear",
            "confusion": "neutral", "curiosity": "neutral",
            "neutral": "neutral", "realization": "neutral", "surprise": "neutral",
        }
        
        print(f"âœ… ëª¨ë¸ ë¡œë“œ ì™„ë£Œ!")
        print(f"   - ì›ë³¸ ë ˆì´ë¸”: {self.num_labels}ê°œ (GoEmotions)")
        print(f"   - ë§¤í•‘ í›„: 7ê°œ (joy, love, gratitude, anger, sadness, fear, neutral)")
        print(f"   - íŒŒë¼ë¯¸í„° ìˆ˜: {self.num_parameters:,}ê°œ")
        print(f"   - ë””ë°”ì´ìŠ¤: {'GPU' if self.device == 0 else 'CPU'}")
    
    async def translate_batch(self, texts):
        """DeepL APIë¡œ ë°°ì¹˜ ë²ˆì—­ (ì‹¤ì œë¡œëŠ” ê°„ë‹¨íˆ ì²˜ë¦¬)"""
        # ì‹¤ì œë¡œëŠ” DeepL API í˜¸ì¶œ
        # ì—¬ê¸°ì„œëŠ” ì‹œë®¬ë ˆì´ì…˜
        print(f"   ğŸŒ {len(texts)}ê°œ ëŒ“ê¸€ ë²ˆì—­ ì¤‘...")
        await asyncio.sleep(0.1)  # ë²ˆì—­ ì‹œê°„ ì‹œë®¬ë ˆì´ì…˜
        return texts  # ì‹¤ì œë¡œëŠ” ë²ˆì—­ëœ í…ìŠ¤íŠ¸ ë°˜í™˜
    
    def predict(self, texts):
        """ëŒ“ê¸€ ë¦¬ìŠ¤íŠ¸ë¥¼ ì…ë ¥ë°›ì•„ ê°ì • ë¶„ì„"""
        # ì˜ì–´ë¡œ ë²ˆì—­ (ì‹¤ì œë¡œëŠ” DeepL ì‚¬ìš©)
        # ì—¬ê¸°ì„œëŠ” ì›ë¬¸ ê·¸ëŒ€ë¡œ ì‚¬ìš© (ì‹œë®¬ë ˆì´ì…˜)
        
        results_raw = self.pipe(texts, batch_size=64)
        
        results = []
        for result in results_raw:
            # ë§¤í•‘ ë° ì„ê³„ê°’ ì ìš©
            mapped_emotions = {}
            for pred in result:
                original_label = pred["label"]
                score = pred["score"]
                
                if score >= self.threshold:
                    mapped_label = self.label_map.get(original_label, "neutral")
                    if mapped_label in mapped_emotions:
                        mapped_emotions[mapped_label] += score
                    else:
                        mapped_emotions[mapped_label] = score
            
            if not mapped_emotions:
                mapped_emotions = {"neutral": 1.0}
            
            # í™•ë¥  ë†’ì€ ìˆœ ì •ë ¬
            sorted_emotions = sorted(
                mapped_emotions.items(),
                key=lambda x: x[1],
                reverse=True
            )
            
            primary_emotion = sorted_emotions[0][0]
            confidence = sorted_emotions[0][1]
            
            results.append({
                'primary_emotion': primary_emotion,
                'confidence': confidence,
                'all_emotions': [e for e, s in sorted_emotions],
                'all_scores': dict(sorted_emotions)
            })
        
        return results


# ============================================================
# í‰ê°€ í•¨ìˆ˜
# ============================================================
def evaluate_model(model, comments_dict):
    """ëª¨ë¸ í‰ê°€ ë° í†µê³„ ê³„ì‚°"""
    print(f"\n{'='*70}")
    print(f"ğŸ” {model.name} í‰ê°€ ì¤‘...")
    print(f"{'='*70}")
    
    # ëŒ“ê¸€ ë¦¬ìŠ¤íŠ¸ ìƒì„±
    comment_ids = list(comments_dict.keys())
    texts = list(comments_dict.values())
    
    # ì²˜ë¦¬ ì‹œê°„ ì¸¡ì •
    start_time = time.time()
    predictions = model.predict(texts)
    processing_time = time.time() - start_time
    
    # í†µê³„ ê³„ì‚°
    confidences = [p['confidence'] for p in predictions]
    avg_confidence = sum(confidences) / len(confidences)
    
    emotion_counts = [len(p['all_emotions']) for p in predictions]
    avg_emotion_count = sum(emotion_counts) / len(emotion_counts)
    
    # ê°ì •ë³„ ë¶„í¬ (ì£¼ìš” ê°ì •)
    primary_emotions = [p['primary_emotion'] for p in predictions]
    emotion_counter = Counter(primary_emotions)
    
    # ê°ì •ë³„ ë°œìƒ ë¹ˆë„ (ì¤‘ë³µ í¬í•¨)
    all_emotions_counter = Counter()
    for p in predictions:
        for emotion in p['all_emotions']:
            all_emotions_counter[emotion] += 1
    
    # ì¹´í…Œê³ ë¦¬ ë§¤í•‘
    emotion_to_category = {
        "joy": "positive",
        "love": "positive",
        "gratitude": "positive",
        "anger": "negative",
        "sadness": "negative",
        "fear": "negative",
        "neutral": "other",
    }
    
    category_counter = Counter()
    for emotion in primary_emotions:
        category = emotion_to_category.get(emotion, "other")
        category_counter[category] += 1
    
    # anger íƒì§€ìœ¨
    anger_count = sum(1 for p in predictions if 'anger' in p['all_emotions'])
    anger_detection_rate = anger_count / len(predictions) * 100
    
    # neutral í¸í–¥ë„ (ì£¼ìš” ê°ì •ì´ neutralì¸ ë¹„ìœ¨)
    neutral_count = sum(1 for p in predictions if p['primary_emotion'] == 'neutral')
    neutral_bias = neutral_count / len(predictions) * 100
    
    print(f"âœ… í‰ê°€ ì™„ë£Œ! (ì²˜ë¦¬ ì‹œê°„: {processing_time:.2f}ì´ˆ)")
    
    return {
        'model_name': model.name,
        'num_parameters': model.num_parameters,
        'num_labels': model.num_labels,
        'processing_time': processing_time,
        'avg_confidence': avg_confidence,
        'avg_emotion_count': avg_emotion_count,
        'emotion_distribution': dict(emotion_counter),
        'all_emotions_frequency': dict(all_emotions_counter),
        'category_distribution': dict(category_counter),
        'anger_detection_rate': anger_detection_rate,
        'neutral_bias': neutral_bias,
        'predictions': predictions,
        'comment_ids': comment_ids,
        'texts': texts,
    }


# ============================================================
# ë¹„êµ í‘œ ìƒì„±
# ============================================================
def generate_comparison_table(results_ko, results_en):
    """ë‘ ëª¨ë¸ì˜ ë¹„êµ í‘œ ìƒì„±"""
    
    print("\n" + "="*100)
    print("ğŸ“Š ëª¨ë¸ ë¹„êµ ìš”ì•½í‘œ")
    print("="*100)
    
    # ê¸°ë³¸ ì •ë³´
    print(f"\n{'='*100}")
    print(f"{'í•­ëª©':<30} {'Fine-tuned KoELECTRA':<35} {'GoEmotions (ì˜ì–´)':<35}")
    print(f"{'='*100}")
    
    print(f"{'ëª¨ë¸ ì´ë¦„':<30} {results_ko['model_name']:<35} {results_en['model_name']:<35}")
    print(f"{'íŒŒë¼ë¯¸í„° ìˆ˜':<30} {results_ko['num_parameters']:,}ê°œ{' '*15} {results_en['num_parameters']:,}ê°œ")
    print(f"{'ê°ì • ë ˆì´ë¸” ìˆ˜':<30} {results_ko['num_labels']}ê°œ{' '*30} {results_en['num_labels']}ê°œ (ì›ë³¸ 28ê°œ)")
    print(f"{'ì–¸ì–´':<30} {'í•œêµ­ì–´ ì§ì ‘':<35} {'ì˜ì–´ (ë²ˆì—­ í•„ìš”)':<35}")
    print(f"{'ë²ˆì—­ í•„ìš”':<30} {'âŒ ë¶ˆí•„ìš”':<35} {'âœ… í•„ìš” (DeepL)':<35}")
    
    # ì„±ëŠ¥ ì§€í‘œ
    print(f"\n{'='*100}")
    print(f"{'ì„±ëŠ¥ ì§€í‘œ':<30} {'Fine-tuned KoELECTRA':<35} {'GoEmotions (ì˜ì–´)':<35}")
    print(f"{'='*100}")
    
    print(f"{'í‰ê·  ì‹ ë¢°ë„':<30} {results_ko['avg_confidence']*100:>6.1f}%{' '*27} {results_en['avg_confidence']*100:>6.1f}%")
    print(f"{'í‰ê·  ê°ì • ê°œìˆ˜':<30} {results_ko['avg_emotion_count']:>6.2f}ê°œ{' '*26} {results_en['avg_emotion_count']:>6.2f}ê°œ")
    print(f"{'ì²˜ë¦¬ ì†ë„ (100ê°œ)':<30} {results_ko['processing_time']:>6.2f}ì´ˆ{' '*26} {results_en['processing_time']:>6.2f}ì´ˆ")
    
    # anger íƒì§€ìœ¨
    print(f"{'anger íƒì§€ìœ¨':<30} {results_ko['anger_detection_rate']:>6.1f}%{' '*27} {results_en['anger_detection_rate']:>6.1f}%")
    print(f"{'neutral í¸í–¥ë„':<30} {results_ko['neutral_bias']:>6.1f}%{' '*27} {results_en['neutral_bias']:>6.1f}%")
    
    # ì¹´í…Œê³ ë¦¬ ë¶„í¬
    print(f"\n{'='*100}")
    print(f"{'ì¹´í…Œê³ ë¦¬ ë¶„í¬':<30} {'Fine-tuned KoELECTRA':<35} {'GoEmotions (ì˜ì–´)':<35}")
    print(f"{'='*100}")
    
    for category in ['positive', 'negative', 'other']:
        ko_count = results_ko['category_distribution'].get(category, 0)
        en_count = results_en['category_distribution'].get(category, 0)
        ko_pct = ko_count / 100 * 100
        en_pct = en_count / 100 * 100
        print(f"{category:<30} {ko_count}ê°œ ({ko_pct:>5.1f}%){' '*18} {en_count}ê°œ ({en_pct:>5.1f}%)")
    
    # ì‹¤ìš©ì„±
    print(f"\n{'='*100}")
    print(f"{'ì‹¤ìš©ì„± í‰ê°€':<30} {'Fine-tuned KoELECTRA':<35} {'GoEmotions (ì˜ì–´)':<35}")
    print(f"{'='*100}")
    
    print(f"{'API ë¹„ìš©':<30} {'ë¬´ë£Œ (ë²ˆì—­ ë¶ˆí•„ìš”)':<35} {'ìœ ë£Œ (DeepL í•„ìš”)':<35}")
    print(f"{'ë„ë©”ì¸ ì í•©ì„±':<30} {'âŒ ë‚®ìŒ (ëŒ€í™” ë°ì´í„°)':<35} {'âš ï¸ ë³´í†µ (Reddit)':<35}")
    print(f"{'ë°°í¬ ìš©ì´ì„±':<30} {'âœ… ì¢‹ìŒ (ì§ì ‘ ì‚¬ìš©)':<35} {'âš ï¸ ë³´í†µ (ë²ˆì—­ í•„ìš”)':<35}")
    
    print(f"\n{'='*100}\n")
    
    # ìƒì„¸ ë¹„êµ (ìƒ˜í”Œ 20ê°œ)
    print(f"\n{'='*100}")
    print(f"ğŸ“‹ ìƒì„¸ ë¹„êµ (ìƒ˜í”Œ 20ê°œ)")
    print(f"{'='*100}\n")
    
    print(f"{'ID':<15} {'ëŒ“ê¸€ (ì¼ë¶€)':<40} {'KoELECTRA':<20} {'GoEmotions':<20}")
    print(f"{'-'*100}")
    
    for i in range(min(20, len(results_ko['texts']))):
        comment_id = results_ko['comment_ids'][i]
        text = results_ko['texts'][i][:37] + '...' if len(results_ko['texts'][i]) > 40 else results_ko['texts'][i]
        
        ko_emotion = results_ko['predictions'][i]['primary_emotion']
        ko_conf = results_ko['predictions'][i]['confidence'] * 100
        
        en_emotion = results_en['predictions'][i]['primary_emotion']
        en_conf = results_en['predictions'][i]['confidence'] * 100
        
        ko_str = f"{ko_emotion}({ko_conf:.0f}%)"
        en_str = f"{en_emotion}({en_conf:.0f}%)"
        
        print(f"{comment_id:<15} {text:<40} {ko_str:<20} {en_str:<20}")
    
    print(f"{'-'*100}\n")


# ============================================================
# CSV ì €ì¥
# ============================================================
def save_detailed_results(results_ko, results_en):
    """ìƒì„¸ ê²°ê³¼ë¥¼ CSVë¡œ ì €ì¥"""
    
    data = []
    for i in range(len(results_ko['texts'])):
        row = {
            'comment_id': results_ko['comment_ids'][i],
            'text': results_ko['texts'][i],
            
            'ko_primary': results_ko['predictions'][i]['primary_emotion'],
            'ko_confidence': results_ko['predictions'][i]['confidence'],
            'ko_all_emotions': ', '.join(results_ko['predictions'][i]['all_emotions']),
            
            'en_primary': results_en['predictions'][i]['primary_emotion'],
            'en_confidence': results_en['predictions'][i]['confidence'],
            'en_all_emotions': ', '.join(results_en['predictions'][i]['all_emotions']),
        }
        data.append(row)
    
    df = pd.DataFrame(data)
    output_path = PROJECT_ROOT / "model_comparison_results.csv"
    df.to_csv(output_path, index=False, encoding='utf-8-sig')
    
    print(f"âœ… ìƒì„¸ ê²°ê³¼ ì €ì¥ ì™„ë£Œ: {output_path}")


# ============================================================
# ë©”ì¸ ì‹¤í–‰
# ============================================================
def main():
    print("\n" + "="*100)
    print("ğŸ”¬ Fine-tuned KoELECTRA vs GoEmotions ëª¨ë¸ ë¹„êµ")
    print("="*100)
    print(f"ğŸ“Š í…ŒìŠ¤íŠ¸ ëŒ“ê¸€: {len(YOUTUBE_COMMENTS_100)}ê°œ")
    
    # ëª¨ë¸ 1: KoELECTRA
    model_ko = KoELECTRAModel()
    results_ko = evaluate_model(model_ko, YOUTUBE_COMMENTS_100)
    
    # ëª¨ë¸ 2: GoEmotions
    model_en = GoEmotionsModel()
    results_en = evaluate_model(model_en, YOUTUBE_COMMENTS_100)
    
    # ë¹„êµ í‘œ ìƒì„±
    generate_comparison_table(results_ko, results_en)
    
    # CSV ì €ì¥
    save_detailed_results(results_ko, results_en)
    
    print("\n" + "="*100)
    print("âœ… ëª¨ë“  ë¹„êµ ì™„ë£Œ!")
    print("="*100)


if __name__ == "__main__":
    main()
