# scripts/test_finetuned_model.py
# fine tuning í•œ ëª¨ë¸ì´ ì‹¤ì œ ìœ íŠœë¸Œ ëŒ“ê¸€ì—ì„œ ì˜ ê°ì • ì„¸ë¶„í™”ë¥¼ í•˜ëŠ”ì§€ í…ŒìŠ¤íŠ¸í•˜ëŠ” ì½”ë“œ
"""
Fine-tuned KoELECTRA ëª¨ë¸ í…ŒìŠ¤íŠ¸
ë’·ê´‘ê³  ì˜ì‹¬ ëŒ“ê¸€ë¡œ ê°ì • ë¶„ë¥˜ ì„±ëŠ¥ í™•ì¸
"""
from __future__ import annotations

import os
import sys
from pathlib import Path

# í”„ë¡œì íŠ¸ ë£¨íŠ¸ ì¶”ê°€
PROJECT_ROOT = Path(__file__).parent.parent
sys.path.insert(0, str(PROJECT_ROOT))

import torch
from transformers import ElectraTokenizer, ElectraForSequenceClassification

# ============================================================
# í…ŒìŠ¤íŠ¸ ë°ì´í„°
# ============================================================
TEST_COMMENTS = {
    "comment_001": "ë’·ê´‘ê³  ì•„ë‹Œê°€ìš”?",
    "comment_002": "í˜‘ì°¬ ë°›ìœ¼ì…¨ë‚˜ìš”?",
    "comment_003": "ëˆ ë°›ê³  í™ë³´í•˜ì‹œëŠ” ê±°ì£ ?",
    "comment_004": "ìŠ¤í°ì„œì‹­ í‘œê¸° ì•ˆ í•˜ì…¨ë„¤ìš”",
    "comment_005": "ê´‘ê³ ì¸ì§€ ë°íˆì„¸ìš”",
    "comment_006": "ì´ê±´ ëª…ë°±í•œ ê´‘ê³ ì¸ë°ìš”",
    "comment_007": "í˜‘ì°¬ ë°›ê³  ê±°ì§“ ë¦¬ë·°",
    "comment_008": "ìœ ë£Œ ê´‘ê³  í‘œì‹œ ì•ˆ í•˜ì…¨ë„¤ìš”",
    "comment_009": "ëˆ ë°›ê³  ì¶”ì²œí•˜ëŠ” ê±° ë§ì£ ?",
    "comment_010": "ë’·ê´‘ê³  ì‹ ê³ í•©ë‹ˆë‹¤"
}

# ============================================================
# Fine-tuned ëª¨ë¸ ë¡œë“œ
# ============================================================
MODEL_PATH = PROJECT_ROOT / "saved_models" / "ko-emotions_finetuned"

print("=" * 70)
print("ğŸ”¬ Fine-tuned KoELECTRA ëª¨ë¸ í…ŒìŠ¤íŠ¸")
print("=" * 70)

print(f"\nğŸ“ ëª¨ë¸ ê²½ë¡œ: {MODEL_PATH}")
print(f"ğŸ“Š í…ŒìŠ¤íŠ¸ ëŒ“ê¸€ ìˆ˜: {len(TEST_COMMENTS)}ê°œ\n")

# ë””ë°”ì´ìŠ¤ ì„¤ì •
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
print(f"ğŸ’» ë””ë°”ì´ìŠ¤: {device}")

# í† í¬ë‚˜ì´ì € & ëª¨ë¸ ë¡œë“œ
print("\nğŸ”„ ëª¨ë¸ ë¡œë”© ì¤‘...")
tokenizer = ElectraTokenizer.from_pretrained(MODEL_PATH)
model = ElectraForSequenceClassification.from_pretrained(MODEL_PATH)
model.to(device)
model.eval()  # í‰ê°€ ëª¨ë“œ
print("âœ… ëª¨ë¸ ë¡œë“œ ì™„ë£Œ!\n")

# Label ì •ë³´ í™•ì¸
id2label = model.config.id2label
label2id = model.config.label2id
print(f"ğŸ·ï¸  ê°ì • ë ˆì´ë¸”: {list(id2label.values())}")
print(f"ğŸ·ï¸  ì´ {len(id2label)}ê°œ í´ë˜ìŠ¤\n")

# ============================================================
# ê°ì • ë¶„ë¥˜ ì‹¤í–‰
# ============================================================
print("=" * 70)
print("ğŸ“Š ê°ì • ë¶„ë¥˜ ê²°ê³¼")
print("=" * 70)

results = []
# â­ ì„ê³„ê°’ ì„¤ì • (15% ì´ìƒì¸ ê°ì •ë§Œ í¬í•¨)
THRESHOLD = 0.15

for comment_id, text in TEST_COMMENTS.items():
    # í† í¬ë‚˜ì´ì§•
    inputs = tokenizer(
        text,
        max_length=128,
        padding='max_length',
        truncation=True,
        return_tensors='pt'
    )
    
    # GPUë¡œ ì´ë™
    inputs = {k: v.to(device) for k, v in inputs.items()}
    
    # ì˜ˆì¸¡
    with torch.no_grad():
        outputs = model(**inputs)
        logits = outputs.logits
        
        # í™•ë¥  ê³„ì‚° (softmax)
        probs = torch.softmax(logits, dim=-1)[0]
        
        # ê°€ì¥ ë†’ì€ í™•ë¥ ì˜ ê°ì •
        pred_id = torch.argmax(probs).item()
        pred_label = id2label[pred_id]
        pred_prob = probs[pred_id].item()
        
        # ìƒìœ„ 3ê°œ ê°ì •
        top3_probs, top3_ids = torch.topk(probs, k=3)
        top3_emotions = [(id2label[idx.item()], prob.item()) 
                        for idx, prob in zip(top3_ids, top3_probs)]
        
        # â­ ì„ê³„ê°’ ì´ìƒì˜ ëª¨ë“  ê°ì • ì¶”ì¶œ
        detected_emotions = []
        for i, prob in enumerate(probs):
            if prob.item() >= THRESHOLD:
                emotion = id2label[i]
                detected_emotions.append((emotion, prob.item()))
        
        # í™•ë¥  ë†’ì€ ìˆœìœ¼ë¡œ ì •ë ¬
        detected_emotions.sort(key=lambda x: x[1], reverse=True)
        
        # ê°ì •ì´ ì—†ìœ¼ë©´ neutral ì¶”ê°€ (ì•ˆì „ì¥ì¹˜)
        if not detected_emotions:
            detected_emotions = [("neutral", probs[label2id["neutral"]].item())]
    
    # ê²°ê³¼ ì €ì¥
    result = {
        'id': comment_id,
        'text': text,
        'predicted': pred_label,  # ì£¼ìš” ê°ì •
        'confidence': pred_prob,
        'top3': top3_emotions,
        'all_emotions': detected_emotions  # â­ ëª¨ë“  ê°ì • (ì„ê³„ê°’ ì´ìƒ)
    }
    results.append(result)
    
    # ì¶œë ¥
    print(f"\nğŸ“ {comment_id}: {text}")
    print(f"   ğŸ¯ ì£¼ìš” ê°ì •: {pred_label} ({pred_prob*100:.1f}%)")
    print(f"   ğŸ“Š Top 3:")
    for emotion, prob in top3_emotions:
        print(f"      - {emotion:12s}: {prob*100:5.1f}%")
    
    # â­ ê°ì§€ëœ ëª¨ë“  ê°ì • í‘œì‹œ (ì„ê³„ê°’ {THRESHOLD*100}% ì´ìƒ)
    print(f"   ğŸ¨ ê°ì§€ëœ ê°ì •ë“¤ (ì„ê³„ê°’ {THRESHOLD*100}% ì´ìƒ):")
    if detected_emotions:
        emotion_labels = [f"{e}({p*100:.1f}%)" for e, p in detected_emotions]
        print(f"      â†’ {', '.join(emotion_labels)}")
    else:
        print(f"      â†’ (ì—†ìŒ)")

# ============================================================
# í†µê³„ ë¶„ì„
# ============================================================
print("\n" + "=" * 70)
print("ğŸ“ˆ í†µê³„ ë¶„ì„")
print("=" * 70)

from collections import Counter

# ê°ì •ë³„ ë¶„í¬ (ì£¼ìš” ê°ì • ê¸°ì¤€)
emotion_counter = Counter([r['predicted'] for r in results])
print(f"\nê°ì •ë³„ ë¶„í¬ (ì£¼ìš” ê°ì •):")
for emotion, count in emotion_counter.most_common():
    percentage = count / len(results) * 100
    print(f"  {emotion:12s}: {count:2d}ê°œ ({percentage:5.1f}%)")

# â­ ê°ì •ë³„ ë°œìƒ ë¹ˆë„ (ì¤‘ë³µ í¬í•¨ - ì„ê³„ê°’ ì´ìƒ)
all_emotions_counter = Counter()
for r in results:
    for emotion, prob in r['all_emotions']:
        all_emotions_counter[emotion] += 1

print(f"\nê°ì •ë³„ ë°œìƒ ë¹ˆë„ (ì„ê³„ê°’ {THRESHOLD*100}% ì´ìƒ, ì¤‘ë³µ ê°€ëŠ¥):")
for emotion, count in all_emotions_counter.most_common():
    percentage = count / len(results) * 100
    print(f"  {emotion:12s}: {count:2d}íšŒ ({percentage:5.1f}%)")

# â­ ê°ì • ì¡°í•© ë¶„ì„
emotion_combinations = Counter()
for r in results:
    # ê°ì • ë ˆì´ë¸”ë§Œ ì¶”ì¶œí•˜ì—¬ íŠœí”Œë¡œ ë³€í™˜
    emotions = tuple([e for e, p in r['all_emotions']])
    emotion_combinations[emotions] += 1

print(f"\nê°ì • ì¡°í•© ë¹ˆë„ (ì„ê³„ê°’ {THRESHOLD*100}% ì´ìƒ):")
for emotions, count in emotion_combinations.most_common():
    emotion_str = ' + '.join(emotions) if emotions else '(ì—†ìŒ)'
    print(f"  {emotion_str:40s}: {count:2d}ê°œ")

# í‰ê·  ì‹ ë¢°ë„
avg_confidence = sum(r['confidence'] for r in results) / len(results)
print(f"\ní‰ê·  ì‹ ë¢°ë„: {avg_confidence*100:.1f}%")

# â­ í‰ê·  ê°ì • ê°œìˆ˜
avg_emotion_count = sum(len(r['all_emotions']) for r in results) / len(results)
print(f"ëŒ“ê¸€ë‹¹ í‰ê·  ê°ì • ê°œìˆ˜: {avg_emotion_count:.2f}ê°œ")

# ê°ì • ë§¤í•‘ (POSITIVE/NEGATIVE/OTHER)
emotion_to_category = {
    "joy": "positive",
    "gratitude": "positive",
    "anger": "negative",
    "sadness": "negative",
    "fear": "negative",
    "neutral": "other",
}

category_counter = Counter()
for r in results:
    category = emotion_to_category[r['predicted']]
    category_counter[category] += 1

print(f"\nì¹´í…Œê³ ë¦¬ë³„ ë¶„í¬:")
for category in ['negative', 'positive', 'other']:
    count = category_counter[category]
    percentage = count / len(results) * 100
    print(f"  {category:12s}: {count:2d}ê°œ ({percentage:5.1f}%)")

print("\n" + "=" * 70)
print("âœ… í…ŒìŠ¤íŠ¸ ì™„ë£Œ!")
print("=" * 70)

# ============================================================
# â­ ìƒì„¸ ê²°ê³¼ í…Œì´ë¸” ì¶œë ¥ (ì„ íƒ)
# ============================================================
print("\n" + "=" * 70)
print("ğŸ“‹ ìƒì„¸ ê²°ê³¼ í…Œì´ë¸”")
print("=" * 70)
print(f"\n{'ID':<15} {'í…ìŠ¤íŠ¸':<30} {'ì£¼ìš” ê°ì •':<12} {'ëª¨ë“  ê°ì •'}")
print("-" * 100)
for r in results:
    text_short = r['text'][:27] + '...' if len(r['text']) > 30 else r['text']
    all_emotions_str = ', '.join([e for e, p in r['all_emotions']])
    print(f"{r['id']:<15} {text_short:<30} {r['predicted']:<12} {all_emotions_str}")
print("-" * 100)