"""
ê°ì • ë¶„ì„ ëª¨ë¸ ì„±ëŠ¥ í‰ê°€: SamLowe/roberta-base-go_emotions
- test_comments_100.py ë°ì´í„°ì…‹ ì‚¬ìš©
- GoEmotions 28ê°œ â†’ 7ê°œ â†’ 3ê°œ(positive/negative/other) ë§¤í•‘
- DeepL APIë¡œ í•œêµ­ì–´ â†’ ì˜ì–´ ë²ˆì—­ í›„ ë¶„ì„
"""
from __future__ import annotations

import re
import time
import asyncio
import httpx
from typing import List, Dict, Tuple
from dataclasses import dataclass
from collections import Counter

import torch
from transformers import AutoTokenizer, AutoModelForSequenceClassification, pipeline

# í…ŒìŠ¤íŠ¸ ë°ì´í„° import
try:
    from scripts.test_comments_100 import TEST_COMMENTS, CATEGORY_INFO, get_stats
except ModuleNotFoundError:
    from test_comments_100 import TEST_COMMENTS, CATEGORY_INFO, get_stats

# DeepL API í‚¤ import
try:
    from src.config import DEEPL_API_KEY
except ModuleNotFoundError:
    try:
        from config import DEEPL_API_KEY
    except ModuleNotFoundError:
        import os
        from dotenv import load_dotenv
        load_dotenv()
        DEEPL_API_KEY = os.getenv("DEEPL_API_KEY")

# ============================================================
# ëª¨ë¸ ì„¤ì •
# ============================================================
_MNAME = "SamLowe/roberta-base-go_emotions"

# GoEmotions 28ê°œ â†’ 7ê°œ ê°ì • ë§¤í•‘
LABEL_MAP = {
    # ê¸ì • ê°ì •ë“¤ â†’ joy (ê¸°ì¨)
    "admiration": "joy", "amusement": "joy", "approval": "joy",
    "excitement": "joy", "joy": "joy", "optimism": "joy",
    "pride": "joy", "relief": "joy",

    # ì• ì • ê´€ë ¨ â†’ love (ì‚¬ë‘)
    "caring": "love", "desire": "love", "love": "love",

    # ê°ì‚¬ â†’ gratitude (ê°ì‚¬)
    "gratitude": "gratitude",

    # ë¶„ë…¸ ê´€ë ¨ â†’ anger (ë¶„ë…¸)
    "anger": "anger", "annoyance": "anger",
    "disapproval": "anger", "disgust": "anger",

    # ìŠ¬í”” ê´€ë ¨ â†’ sadness (ìŠ¬í””)
    "disappointment": "sadness", "embarrassment": "sadness",
    "grief": "sadness", "remorse": "sadness", "sadness": "sadness",

    # ë‘ë ¤ì›€ ê´€ë ¨ â†’ fear (ë‘ë ¤ì›€)
    "fear": "fear", "nervousness": "fear",

    # ì¤‘ë¦½/ê¸°íƒ€ â†’ neutral
    "confusion": "neutral", "curiosity": "neutral",
    "neutral": "neutral", "realization": "neutral", "surprise": "neutral",
}

# 7ê°œ ê°ì • â†’ 3ê°œ ì¹´í…Œê³ ë¦¬ ë§¤í•‘
DETAIL_TO_SENTIMENT = {
    "joy": "positive",
    "love": "positive",
    "gratitude": "positive",
    "anger": "negative",
    "sadness": "negative",
    "fear": "negative",
    "neutral": "other",
}

# ê³µìœ  ëª¨ë¸
_pipe = None


def _get_pipeline():
    """ëª¨ë¸ ì§€ì—° ë¡œë”©"""
    global _pipe
    if _pipe is None:
        print("[INFO] GoEmotions ëª¨ë¸ ë¡œë”© ì¤‘...")
        tok = AutoTokenizer.from_pretrained(_MNAME)
        model = AutoModelForSequenceClassification.from_pretrained(_MNAME)
        _pipe = pipeline(
            task="text-classification",
            model=model,
            tokenizer=tok,
            device=0 if torch.cuda.is_available() else -1,
            top_k=3,  # ìƒìœ„ 3ê°œ ê°ì • ë°˜í™˜
            truncation=True,
            max_length=512,
        )
        print("[SUCCESS] GoEmotions ëª¨ë¸ ë¡œë”© ì™„ë£Œ!")
    return _pipe


# ============================================================
# DeepL ë²ˆì—­ í•¨ìˆ˜
# ============================================================
def _is_english(text: str) -> bool:
    """ì˜ì–´ì¸ì§€ í™•ì¸"""
    cleaned = re.sub(r"[^\w\s.,!?\'\"-]", "", text or "")
    return bool(re.fullmatch(r"[A-Za-z0-9\s\.,;:'\"!?()\[\]{}@#$%^&*_\-=+/<>|~]+", cleaned))


async def translate_to_english(texts: List[str]) -> List[str]:
    """DeepL APIë¡œ í•œêµ­ì–´ â†’ ì˜ì–´ ë²ˆì—­ (ë¹„ë™ê¸°)"""
    if not DEEPL_API_KEY:
        print("[WARN] DEEPL_API_KEYê°€ ì—†ìŠµë‹ˆë‹¤. ì›ë¬¸ìœ¼ë¡œ ë¶„ì„í•©ë‹ˆë‹¤.")
        return texts
    
    url = "https://api.deepl.com/v2/translate"
    translated: List[str] = []
    
    async with httpx.AsyncClient(timeout=20.0) as client:
        for text in texts:
            if _is_english(text):
                translated.append(text)
                continue
            
            try:
                response = await client.post(
                    url,
                    data={
                        "auth_key": DEEPL_API_KEY,
                        "text": text,
                        "target_lang": "EN"
                    }
                )
                response.raise_for_status()
                result = response.json()
                translated.append(result["translations"][0]["text"])
            except Exception as e:
                print(f"[WARN] ë²ˆì—­ ì‹¤íŒ¨: {text[:20]}... â†’ ì›ë¬¸ ì‚¬ìš©")
                translated.append(text)
    
    return translated


def translate_sync(texts: List[str]) -> List[str]:
    """ë™ê¸° ë²„ì „ ë²ˆì—­ í•¨ìˆ˜"""
    return asyncio.run(translate_to_english(texts))


# ============================================================
# ê²°ê³¼ ë°ì´í„° í´ë˜ìŠ¤
# ============================================================
@dataclass
class SentimentResult:
    text: str
    translated: str
    expected: str  # ì •ë‹µ ë¼ë²¨ (positive/negative/other)
    predicted: str  # ì˜ˆì¸¡ ë¼ë²¨
    detail_emotions: List[str]  # 7ê°œ ê°ì • ì¤‘ ê°ì§€ëœ ê²ƒë“¤
    correct: bool


# ============================================================
# ê°ì • ë¶„ì„ í•¨ìˆ˜
# ============================================================
def analyze_sentiment(texts: List[str]) -> Tuple[List[str], List[List[str]], float]:
    """
    ê°ì • ë¶„ì„ ìˆ˜í–‰
    
    Returns:
        (ì˜ˆì¸¡ ë¼ë²¨ ë¦¬ìŠ¤íŠ¸, ì„¸ë¶€ ê°ì • ë¦¬ìŠ¤íŠ¸, ì²˜ë¦¬ ì‹œê°„)
    """
    pipe = _get_pipeline()
    
    start = time.time()
    results = pipe(texts, batch_size=64, truncation=True, max_length=512)
    elapsed_ms = (time.time() - start) * 1000
    
    predictions = []
    detail_emotions_list = []
    
    for result in results:
        # ê°ì •ê³¼ ì ìˆ˜ë¥¼ í•¨ê»˜ ì €ì¥
        emotion_scores = {}
        
        for pred in result:
            original_label = pred["label"]
            score = pred["score"]
            
            # 15% ì´ìƒì¸ ê°ì •ë§Œ í¬í•¨
            if score >= 0.15:
                detail_emotion = LABEL_MAP.get(original_label, "neutral")
                if detail_emotion not in emotion_scores or score > emotion_scores[detail_emotion]:
                    emotion_scores[detail_emotion] = score
        
        # neutralê³¼ ë‹¤ë¥¸ ê°ì •ì´ í•¨ê»˜ ìˆì„ ë•Œ ì²˜ë¦¬
        if "neutral" in emotion_scores and len(emotion_scores) > 1:
            neutral_score = emotion_scores["neutral"]
            other_emotions = {k: v for k, v in emotion_scores.items() if k != "neutral"}
            max_other_score = max(other_emotions.values())
            
            if max_other_score >= neutral_score:
                del emotion_scores["neutral"]
            else:
                emotion_scores = {"neutral": neutral_score}
        
        # ê°ì •ì´ ì—†ìœ¼ë©´ neutral ì¶”ê°€
        if not emotion_scores:
            emotion_scores = {"neutral": 0.0}
        
        # ì ìˆ˜ ë†’ì€ ìˆœìœ¼ë¡œ ì •ë ¬
        detail_emotions = sorted(
            emotion_scores.keys(),
            key=lambda x: emotion_scores[x],
            reverse=True
        )
        
        # ìµœì¢… ê°ì • ê²°ì • (ê°€ì¥ ë†’ì€ ì ìˆ˜)
        primary_emotion = detail_emotions[0]
        sentiment_type = DETAIL_TO_SENTIMENT[primary_emotion]
        
        predictions.append(sentiment_type)
        detail_emotions_list.append(detail_emotions)
    
    return predictions, detail_emotions_list, elapsed_ms


# ============================================================
# ë©”íŠ¸ë¦­ ê³„ì‚°
# ============================================================
def calculate_metrics(predictions: List[str], ground_truth: List[str]) -> Dict:
    """ë‹¤ì¤‘ í´ë˜ìŠ¤ ë¶„ë¥˜ ë©”íŠ¸ë¦­ ê³„ì‚°"""
    classes = ["positive", "negative", "other"]
    
    # ì „ì²´ ì •í™•ë„
    correct = sum(1 for p, g in zip(predictions, ground_truth) if p == g)
    accuracy = correct / len(predictions) if predictions else 0
    
    # í´ë˜ìŠ¤ë³„ ë©”íŠ¸ë¦­
    class_metrics = {}
    for cls in classes:
        tp = sum(1 for p, g in zip(predictions, ground_truth) if p == cls and g == cls)
        fp = sum(1 for p, g in zip(predictions, ground_truth) if p == cls and g != cls)
        fn = sum(1 for p, g in zip(predictions, ground_truth) if p != cls and g == cls)
        tn = sum(1 for p, g in zip(predictions, ground_truth) if p != cls and g != cls)
        
        precision = tp / (tp + fp) if (tp + fp) > 0 else 0
        recall = tp / (tp + fn) if (tp + fn) > 0 else 0
        f1 = 2 * precision * recall / (precision + recall) if (precision + recall) > 0 else 0
        
        class_metrics[cls] = {
            "precision": precision,
            "recall": recall,
            "f1": f1,
            "tp": tp,
            "fp": fp,
            "fn": fn,
            "tn": tn,
            "support": tp + fn  # ì‹¤ì œ í•´ë‹¹ í´ë˜ìŠ¤ ê°œìˆ˜
        }
    
    # Macro Average (í´ë˜ìŠ¤ë³„ í‰ê· )
    macro_precision = sum(m["precision"] for m in class_metrics.values()) / len(classes)
    macro_recall = sum(m["recall"] for m in class_metrics.values()) / len(classes)
    macro_f1 = sum(m["f1"] for m in class_metrics.values()) / len(classes)
    
    return {
        "accuracy": accuracy,
        "macro_precision": macro_precision,
        "macro_recall": macro_recall,
        "macro_f1": macro_f1,
        "class_metrics": class_metrics,
    }


# ============================================================
# Confusion Matrix ìƒì„±
# ============================================================
def create_confusion_matrix(predictions: List[str], ground_truth: List[str]) -> Dict:
    """Confusion Matrix ìƒì„±"""
    classes = ["positive", "negative", "other"]
    matrix = {actual: {pred: 0 for pred in classes} for actual in classes}
    
    for pred, actual in zip(predictions, ground_truth):
        matrix[actual][pred] += 1
    
    return matrix


# ============================================================
# ë©”ì¸ í‰ê°€ í•¨ìˆ˜
# ============================================================
def evaluate_sentiment():
    """ê°ì • ë¶„ì„ ëª¨ë¸ í‰ê°€ ì‹¤í–‰"""
    print("\n" + "=" * 70)
    print("ğŸ­ ê°ì • ë¶„ì„ ëª¨ë¸ ì„±ëŠ¥ í‰ê°€: GoEmotions")
    print("=" * 70)
    print("ğŸ“ ë°ì´í„°: test_comments_100.py (100ê°œ ëŒ“ê¸€)")
    print("ğŸŒ ë²ˆì—­: DeepL API (í•œêµ­ì–´ â†’ ì˜ì–´)")
    print(f"ğŸ¤– ëª¨ë¸: {_MNAME}")
    
    # API í‚¤ í™•ì¸
    if DEEPL_API_KEY:
        print("âœ… DEEPL_API_KEY ë¡œë“œ ì™„ë£Œ")
    else:
        print("âš ï¸ DEEPL_API_KEY ì—†ìŒ - ì›ë¬¸ìœ¼ë¡œ ë¶„ì„ë©ë‹ˆë‹¤")
    
    # í†µê³„ ì¶œë ¥
    stats = get_stats()
    print(f"\n[í…ŒìŠ¤íŠ¸ ë°ì´í„° êµ¬ì„±]")
    print(f"  ì´ ëŒ“ê¸€: {stats['total']}ê°œ")
    print(f"  ğŸ˜Š ê¸ì • (positive): {stats['positive']}ê°œ")
    print(f"  ğŸ˜¢ ë¶€ì • (negative): {stats['negative']}ê°œ")
    print(f"  ğŸ˜ ì¤‘ë¦½ (other): {stats['other']}ê°œ")
    
    # ë°ì´í„° ì¶”ì¶œ
    texts = [t[0] for t in TEST_COMMENTS]
    ground_truth = [t[2] for t in TEST_COMMENTS]  # ê°ì • ë¼ë²¨
    
    print(f"\n{'='*70}")
    print(f"[í‰ê°€ ì‹œì‘] ì´ {len(texts)}ê°œ ëŒ“ê¸€ ë¶„ì„")
    print(f"{'='*70}\n")
    
    # 1. ë²ˆì—­
    print("[ë²ˆì—­] DeepL APIë¡œ í•œêµ­ì–´ â†’ ì˜ì–´ ë²ˆì—­ ì¤‘...")
    translate_start = time.time()
    translated_texts = translate_sync(texts)
    translate_time = (time.time() - translate_start) * 1000
    print(f"       ì™„ë£Œ! ({translate_time:.1f}ms)")
    
    # ë²ˆì—­ ìƒ˜í”Œ
    print("\n[ë²ˆì—­ ìƒ˜í”Œ]")
    for i in [0, 20, 55]:
        if i < len(texts):
            print(f"  ì›ë¬¸: {texts[i][:30]}...")
            print(f"  ë²ˆì—­: {translated_texts[i][:50]}...")
            print()
    
    # 2. ê°ì • ë¶„ì„
    print("[ë¶„ì„] GoEmotions ëª¨ë¸ë¡œ ê°ì • ë¶„ì„ ì¤‘...")
    predictions, detail_emotions_list, analysis_time = analyze_sentiment(translated_texts)
    print(f"       ì™„ë£Œ! ({analysis_time:.1f}ms)")
    
    # 3. ê²°ê³¼ ìƒì„±
    results = []
    for i, (text, expected, pred, details) in enumerate(zip(texts, ground_truth, predictions, detail_emotions_list)):
        results.append(SentimentResult(
            text=text,
            translated=translated_texts[i],
            expected=expected,
            predicted=pred,
            detail_emotions=details,
            correct=(expected == pred)
        ))
    
    # 4. ë©”íŠ¸ë¦­ ê³„ì‚°
    metrics = calculate_metrics(predictions, ground_truth)
    confusion = create_confusion_matrix(predictions, ground_truth)
    
    # 5. ê²°ê³¼ ì¶œë ¥
    print_results(results, metrics, confusion, analysis_time)
    
    # 6. ì¹´í…Œê³ ë¦¬ë³„ ë¶„ì„
    analyze_by_category(results)
    
    print("\n" + "=" * 70)
    print("âœ… ê°ì • ë¶„ì„ í‰ê°€ ì™„ë£Œ!")
    print("=" * 70 + "\n")


def print_results(results: List[SentimentResult], metrics: Dict, 
                  confusion: Dict, time_ms: float):
    """ê²°ê³¼ ì¶œë ¥"""
    
    print(f"\n{'='*70}")
    print("ğŸ“Š ê°œë³„ ëŒ“ê¸€ ë¶„ì„ ê²°ê³¼")
    print(f"{'='*70}")
    print(f"{'#':<4} {'ì •ë‹µ':<10} {'ì˜ˆì¸¡':<10} {'ê²°ê³¼':<6} {'ì„¸ë¶€ê°ì •':<20} ëŒ“ê¸€")
    print("-" * 70)
    
    emoji_map = {
        "positive": "ğŸ˜Šê¸ì •",
        "negative": "ğŸ˜¢ë¶€ì •",
        "other": "ğŸ˜ì¤‘ë¦½"
    }
    
    for i, r in enumerate(results, 1):
        expected_str = emoji_map[r.expected]
        predicted_str = emoji_map[r.predicted]
        correct_str = "âœ…" if r.correct else "âŒ"
        details_str = ", ".join(r.detail_emotions[:2])
        text_preview = r.text[:20] + "..." if len(r.text) > 20 else r.text
        
        print(f"{i:<4} {expected_str:<10} {predicted_str:<10} {correct_str:<6} {details_str:<20} {text_preview}")
    
    # ì„±ëŠ¥ ìš”ì•½
    print(f"\n{'='*70}")
    print("ğŸ“ˆ ì„±ëŠ¥ ìš”ì•½")
    print(f"{'='*70}")
    print(f"{'ë©”íŠ¸ë¦­':<25} {'ê°’':<15}")
    print("-" * 40)
    print(f"{'ì •í™•ë„ (Accuracy)':<25} {metrics['accuracy']*100:>6.1f}%")
    print(f"{'Macro Precision':<25} {metrics['macro_precision']*100:>6.1f}%")
    print(f"{'Macro Recall':<25} {metrics['macro_recall']*100:>6.1f}%")
    print(f"{'Macro F1 Score':<25} {metrics['macro_f1']*100:>6.1f}%")
    print(f"{'ì²˜ë¦¬ ì‹œê°„':<25} {time_ms:>6.1f}ms")
    
    # í´ë˜ìŠ¤ë³„ ì„±ëŠ¥
    print(f"\n{'='*70}")
    print("ğŸ“Š í´ë˜ìŠ¤ë³„ ì„±ëŠ¥")
    print(f"{'='*70}")
    print(f"{'í´ë˜ìŠ¤':<12} {'Precision':<12} {'Recall':<12} {'F1 Score':<12} {'Support':<10}")
    print("-" * 58)
    
    for cls, m in metrics["class_metrics"].items():
        cls_name = emoji_map[cls]
        print(f"{cls_name:<12} {m['precision']*100:>6.1f}%{'':<5} {m['recall']*100:>6.1f}%{'':<5} "
              f"{m['f1']*100:>6.1f}%{'':<5} {m['support']:>4}ê°œ")
    
    # Confusion Matrix
    print(f"\n{'='*70}")
    print("ğŸ”¢ Confusion Matrix")
    print(f"{'='*70}")
    print(f"\n{'':>15} {'ì˜ˆì¸¡:ê¸ì •':>12} {'ì˜ˆì¸¡:ë¶€ì •':>12} {'ì˜ˆì¸¡:ì¤‘ë¦½':>12}")
    
    for actual in ["positive", "negative", "other"]:
        actual_name = {"positive": "ì‹¤ì œ:ê¸ì •", "negative": "ì‹¤ì œ:ë¶€ì •", "other": "ì‹¤ì œ:ì¤‘ë¦½"}[actual]
        row = confusion[actual]
        print(f"{actual_name:>15} {row['positive']:>12} {row['negative']:>12} {row['other']:>12}")


def analyze_by_category(results: List[SentimentResult]):
    """ì¹´í…Œê³ ë¦¬ë³„ ë¶„ì„"""
    
    print(f"\n{'='*70}")
    print("ğŸ“‚ ì¹´í…Œê³ ë¦¬ë³„ ë¶„ì„ ê²°ê³¼")
    print(f"{'='*70}")
    
    for cat_name, info in CATEGORY_INFO.items():
        start, end = info["range"]
        expected_sentiment = info.get("expected_sentiment", "mixed")
        
        cat_results = results[start:end]
        correct_count = sum(1 for r in cat_results if r.correct)
        total = len(cat_results)
        
        # ì˜ˆì¸¡ ë¶„í¬
        pred_counter = Counter(r.predicted for r in cat_results)
        
        print(f"\n[{cat_name}] ({total}ê°œ)")
        print(f"  ê¸°ëŒ€ ê°ì •: {expected_sentiment}")
        print(f"  ì •í™•ë„: {correct_count}/{total} ({correct_count/total*100:.1f}%)")
        print(f"  ì˜ˆì¸¡ ë¶„í¬: ğŸ˜Š{pred_counter.get('positive', 0)} | ğŸ˜¢{pred_counter.get('negative', 0)} | ğŸ˜{pred_counter.get('other', 0)}")


# ============================================================
# ë©”ì¸ ì‹¤í–‰
# ============================================================
if __name__ == "__main__":
    evaluate_sentiment()