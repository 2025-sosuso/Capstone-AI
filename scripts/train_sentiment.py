# scripts/train_sentiment.py
"""
KoELECTRA ê°ì • ë¶„ì„ ëª¨ë¸ Fine-tuning
- ë°ì´í„°: AI Hub ê°ì„±ëŒ€í™”ë§ë­‰ì¹˜ (ì „ì²˜ë¦¬ ì™„ë£Œ)
- ëª¨ë¸: monologg/koelectra-base-v3-goemotions
- ëª©í‘œ: 6ê°œ ê°ì • ë¶„ë¥˜ (joy, gratitude, anger, sadness, fear, neutral)
"""
from __future__ import annotations

import os
import sys
import warnings
from pathlib import Path
import pandas as pd
import torch
from torch.utils.data import Dataset, DataLoader
from torch.optim import AdamW  # 
from transformers import (
    ElectraForSequenceClassification,
    ElectraTokenizer,
    get_linear_schedule_with_warmup
)
from tqdm import tqdm
import json
from datetime import datetime
from sklearn.metrics import classification_report, confusion_matrix
import numpy as np
import time

# ============================================================
# Windows í•œê¸€ ì„¤ì •
# ============================================================
if sys.platform == 'win32':
    os.environ['PYTHONIOENCODING'] = 'utf-8'
    if hasattr(sys.stdout, 'reconfigure'):
        try:
            sys.stdout.reconfigure(encoding='utf-8')
        except Exception:
            pass

os.environ["HF_HUB_DISABLE_SYMLINKS_WARNING"] = "1"
warnings.filterwarnings("ignore")

# ============================================================
# í”„ë¡œì íŠ¸ ë£¨íŠ¸ ê²½ë¡œ ì„¤ì •
# ============================================================
SCRIPT_DIR = Path(__file__).parent  # scripts/
PROJECT_ROOT = SCRIPT_DIR.parent     # capstone-ai/

# ============================================================
# ì„¤ì •
# ============================================================
CONFIG = {
    'model_name': 'monologg/koelectra-base-v3-goemotions',
    
    # ë°ì´í„° ê²½ë¡œ (ì „ì²˜ë¦¬ ì™„ë£Œëœ ë°ì´í„°)
    'train_data_path': PROJECT_ROOT / 'data' / 'processed' / 'trainProcessed' / 'train_processed.csv',
    'val_data_path': PROJECT_ROOT / 'data' / 'processed' / 'valProcessed' / 'val_processed.csv',
    
    # ëª¨ë¸ ì €ì¥ ìœ„ì¹˜
    'output_dir': PROJECT_ROOT / 'saved_models' / 'ko-emotions_finetuned',
    
    # â­ ì‹¤í—˜ ID (ì‹¤í—˜ë§ˆë‹¤ ë³€ê²½í•˜ì„¸ìš”!)
    'experiment_id': 'exp_4_32',
    
    # í•™ìŠµ í•˜ì´í¼íŒŒë¼ë¯¸í„°
    # batch size vs epoch vs iterarion
    # batch size: ì „ì²´ ë°ì´í„° ì…‹ì„ ì—¬ëŸ¬ ì†Œê·¸ë£¹ìœ¼ë¡œ ë‚˜ëˆ´ì„ ë•Œ í•˜ë‚˜ì˜ ì†Œê·¸ë£¹ì— ì†í•˜ëŠ” ë°ì´í„° ìˆ˜ / 
    #             í¬ë©´: í•™ìŠµ ì†ë„ ëŠë¦¼, ë©”ëª¨ë¦¬ ë¶€ì¡± / ì‘ìœ¼ë©´: ì ì€ ë°ì´í„°ë¡œ ê°€ì¤‘ì¹˜ê°€ ìì£¼ ì—…ë°ì´íŠ¸ë¼ì„œ í›ˆë ¨ ë¶ˆì•ˆì •
    # epoch: ëª¨ë“  ë°ì´í„°ì…‹ì„ í•™ìŠµí•˜ëŠ” íšŸìˆ˜
    #        í¬ë©´: overfitting ë°œìƒí•  í™•ë¥  ë†’ìŒ / ì‘ìœ¼ë©´: underfitting ë°œìƒí•  í™•ë¥  ë†’ìŒ
    # iteration: 1-epochë¥¼ ë§ˆì¹˜ëŠ”ë° í•„ìš”í•œ ë¯¸ë‹ˆë°°ì¹˜ ìˆ˜(=1-epochì—ì„œ íŒŒë¼ë¯¸í„° ì—…ë°ì´íŠ¸ íšŸìˆ˜). ë”°ë¼ì„œ ì „ì²´ ë°ì´í„° ìˆ˜ / batch size 
    'batch_size': 32,          # RTX 4090ì´ë©´ 64ê¹Œì§€ ê°€ëŠ¥
    'epochs': 4,               
    'learning_rate_encoder': 2e-5,      # ì¸ì½”ë”: ë¯¸ì„¸ ì¡°ì •
    'learning_rate_classifier': 1e-3,   # Classifier: ìƒˆë¡œ í•™ìŠµ
    'max_length': 128,         # ìµœëŒ€ í† í° ê¸¸ì´
    'warmup_steps': 100,       # Warmup ìŠ¤í…
    'weight_decay': 0.01,      # ì •ê·œí™”
    
    # ê°ì • ë ˆì´ë¸” (ì „ì²˜ë¦¬ëœ ë°ì´í„°ì™€ ë™ì¼)
    'labels': ['joy', 'gratitude', 'anger', 'sadness', 'fear', 'neutral']  # ë°ì´í„°ì…‹ì— loveê°€ ì—†ì–´ì„œ ìš°ì„  ëºŒ
}

# ============================================================
# Dataset í´ë˜ìŠ¤
# ============================================================
class EmotionDataset(Dataset):
    """
    ê°ì„±ëŒ€í™”ë§ë­‰ì¹˜ Dataset
    ì»¬ëŸ¼: ì‚¬ëŒë¬¸ì¥1, goemotion_label
    """
    def __init__(self, csv_path, tokenizer, max_length, label2id):
        print(f"[INFO] ë°ì´í„° ë¡œë”©: {csv_path}")
        self.df = pd.read_csv(csv_path)
        self.tokenizer = tokenizer
        self.max_length = max_length
        self.label2id = label2id
        
        # ë°ì´í„° í™•ì¸
        print(f"[INFO] ì´ {len(self.df)}ê°œ ìƒ˜í”Œ")
        print(f"[INFO] ê°ì • ë¶„í¬:")
        print(self.df['goemotion_label'].value_counts())
        
    def __len__(self):
        return len(self.df)
    
    def __getitem__(self, idx):
        row = self.df.iloc[idx]
        text = str(row['ì‚¬ëŒë¬¸ì¥1'])  # ì»¬ëŸ¼ëª… ì£¼ì˜!
        label = row['goemotion_label']
        
        # í† í¬ë‚˜ì´ì§•
        encoding = self.tokenizer(
            text,
            max_length=self.max_length,
            padding='max_length',
            truncation=True,
            return_tensors='pt'
        )
        
        return {
            'input_ids': encoding['input_ids'].squeeze(),
            'attention_mask': encoding['attention_mask'].squeeze(),
            'labels': torch.tensor(self.label2id[label], dtype=torch.long)
        }

# ============================================================
# í‰ê°€ í•¨ìˆ˜
# ============================================================
def evaluate(model, dataloader, device, id2label):
    """
    ëª¨ë¸ í‰ê°€ ë° ìƒì„¸ ë©”íŠ¸ë¦­ ê³„ì‚°
    """
    model.eval()
    total_loss = 0
    all_preds = []
    all_labels = []
    
    eval_start_time = time.time()
    
    with torch.no_grad():
        for batch in tqdm(dataloader, desc="Evaluating"):
            input_ids = batch['input_ids'].to(device)
            attention_mask = batch['attention_mask'].to(device)  # NLP ëŠ” ì…ë ¥ì— ë„£ëŠ” ë¬¸ì¥ë“¤ì´ ê¸¸ì´ë“¤ì´ ê°™ì•„ì•¼ í•¨. ê·¸ë˜ì„œ ê¸¸ì´ë¥¼ ì§€ì •í•´ì¤¬ê³  ì§€ì •ëœ ê¸¸ì´ë³´ë‹¤ ì§§ìœ¼ë©´ ê°€ì§œ í† í°ì„ ë„£ì–´ì¤Œ. 
                                                                # ì´ë•Œ ì–´ë–¤ í† í°ì´ ì§„ì§œê³  ê°€ì§œì¸ì§€ ì•Œë ¤ì£¼ëŠ” ê²Œ attention_mask ì—­í• ì„
            labels = batch['labels'].to(device)
            
            outputs = model(
                input_ids=input_ids,
                attention_mask=attention_mask,
                labels=labels
            )
            
            total_loss += outputs.loss.item()
            
            predictions = torch.argmax(outputs.logits, dim=-1)
            all_preds.extend(predictions.cpu().numpy())
            all_labels.extend(labels.cpu().numpy())
    
    eval_time = time.time() - eval_start_time
    
    avg_loss = total_loss / len(dataloader)
    accuracy = np.mean(np.array(all_preds) == np.array(all_labels))
    
    # ìƒì„¸ ë¦¬í¬íŠ¸
    label_names = [id2label[i] for i in range(len(id2label))]
    report = classification_report(
        all_labels, 
        all_preds, 
        target_names=label_names,
        output_dict=True,
        zero_division=0
    )
    
    return avg_loss, accuracy, report, all_preds, all_labels, eval_time

# ============================================================
# í•™ìŠµ í•¨ìˆ˜
# ============================================================
def train():
    total_start_time = time.time()
    
    print("=" * 70)
    print(f"ğŸ”¬ ì‹¤í—˜: {CONFIG['experiment_id']}")
    print("=" * 70)
    
    print(f"\nğŸ“ í”„ë¡œì íŠ¸ ë£¨íŠ¸: {PROJECT_ROOT}")
    print(f"ğŸ“ Training ë°ì´í„°: {CONFIG['train_data_path']}")
    print(f"ğŸ“ Validation ë°ì´í„°: {CONFIG['val_data_path']}")
    print(f"ğŸ“ ëª¨ë¸ ì €ì¥ ìœ„ì¹˜: {CONFIG['output_dir']}\n")
    
    device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
    print(f"ğŸ’» ì‚¬ìš© ë””ë°”ì´ìŠ¤: {device}")
    if device.type == "cuda":
        print(f"   GPU: {torch.cuda.get_device_name(0)}")
        print(f"   GPU ë©”ëª¨ë¦¬: {torch.cuda.get_device_properties(0).total_memory / 1024**3:.2f} GB\n")
    
    # Label mapping
    label2id = {label: idx for idx, label in enumerate(CONFIG['labels'])}  # labels(ê°ì •7ê°€ì§€)ì— index ë¶€ì—¬ -> ex.{'joy':0, 'love':1}
    id2label = {idx: label for label, idx in label2id.items()}  # ex.{0:'joy', 1:'love'}
    
    print(f"ğŸ·ï¸  ê°ì • ë ˆì´ë¸”: {CONFIG['labels']}")
    print(f"ğŸ·ï¸  ì´ {len(CONFIG['labels'])}ê°œ í´ë˜ìŠ¤\n")
    
    print("ğŸ”„ ëª¨ë¸ ë¡œë”© ì¤‘...")
    tokenizer = ElectraTokenizer.from_pretrained(CONFIG['model_name'])
    model = ElectraForSequenceClassification.from_pretrained(
        CONFIG['model_name'],
        num_labels=len(CONFIG['labels']),
        id2label=id2label,
        label2id=label2id,
        use_safetensors=True,
        ignore_mismatched_sizes=True  # Classifier í¬ê¸°ê°€ ë‹¤ë¥¼ ìˆ˜ ìˆìŒ
    )
    model.to(device)
    print("âœ… ëª¨ë¸ ë¡œë“œ ì™„ë£Œ\n")
    
    # Dataset & DataLoader
    # Dataset: ë°ì´í„°ë¥¼ ë³´ê´€í•˜ê³  í•œ ê°œì”© êº¼ë‚´ì£¼ëŠ” ê³³
    # DataLoader: Datasetì—ì„œ ë°ì´í„°ë¥¼ ì—¬ëŸ¬ ê°œì”© ë¬¶ì–´ì„œ ëª¨ë¸ì—ê²Œ ìš´ë°˜
    print("ğŸ“Š ë°ì´í„°ì…‹ ë¡œë”© ì¤‘...")
    train_dataset = EmotionDataset(
        CONFIG['train_data_path'],
        tokenizer,
        CONFIG['max_length'],
        label2id
    )
    val_dataset = EmotionDataset(
        CONFIG['val_data_path'],
        tokenizer,
        CONFIG['max_length'],
        label2id
    )
    
    train_loader = DataLoader(
        train_dataset,
        batch_size=CONFIG['batch_size'],  # batch_size: ëª¨ë¸ì— ë„£ì„ ë°ì´í„°ë¥¼ í•œ ë²ˆì— ëª‡ ê°œ ë„£ì„ê±´ì§€ ì§€ì •
        shuffle=True,
        num_workers=0  # Windowsì—ì„œëŠ” 0
    )
    val_loader = DataLoader(
        val_dataset,
        batch_size=CONFIG['batch_size'],
        shuffle=False,
        num_workers=0
    )
    
    print(f"\nâœ… Training ë°ì´í„°: {len(train_dataset):,}ê°œ")
    print(f"âœ… Validation ë°ì´í„°: {len(val_dataset):,}ê°œ")
    print(f"âœ… Batch size: {CONFIG['batch_size']}")
    print(f"âœ… Total batches per epoch: {len(train_loader)}\n")
    
    # Optimizer & Scheduler (Differential Learning Rate)
    print("âš™ï¸  Optimizer ì„¤ì •...")
    optimizer = AdamW([
        {
            'params': model.electra.parameters(),  # ì¸ì½”ë”
            'lr': CONFIG['learning_rate_encoder'],
            'weight_decay': CONFIG['weight_decay']  # ì •ê·œí™”, weight=weight-(lr*gradient)-(weight_decay*weight)->weight_decay*weightë¡œ ì¸í•´ weight ì¡°ê¸ˆì”© ì¤„ì„(ê·œì œ)
        },
        {
            'params': model.classifier.parameters(),  # Classifier
            'lr': CONFIG['learning_rate_classifier'],  # learning rate: gradient descentì—ì„œ ìµœì ê°’ì„ ì°¾ì„ ë•Œ ìµœì†Ÿê°’ì„ ë‚´ë ¤ê°€ëŠ” í¬ë³µì˜ í¬ê¸°, lrê°€ í¬ë©´->overshootingë°œìƒ, lrê°€ ì‘ìœ¼ë©´->local mininumë°œìƒ, ì ë‹¹í•œ ê°’ ì°¾ëŠ”ê²Œ ì¢‹ìŒ
            'weight_decay': CONFIG['weight_decay']  # weight_decay: weight ê°’ë“¤ì˜ ì¦ê°€ë¥¼ ì œí•œí•´ì„œ ëª¨ë¸ì˜ ë³µì¡ë„ ê°ì†Œ ì‹œí‚´, ëª¨ë¸ì´ ë³µì¡í•´ì§€ë©´?->overfittingë°œìƒ
        }
    ])
    
    total_steps = len(train_loader) * CONFIG['epochs']
    # scheduler: ì‹œê°„ì— ë”°ë¼ lr ì¡°ì •í•˜ëŠ” ì—­í•  
    # ex. step 1~100->warmup, step100~2000->lrê°’ìœ ì§€, step2000~4000->lrê°’ decay => ì´ ë‚´ìš©ì€ transformers library ì•ˆì— ìˆìŒ
    scheduler = get_linear_schedule_with_warmup(
        optimizer,
        num_warmup_steps=CONFIG['warmup_steps'],
        num_training_steps=total_steps
    )
    
    print(f"   Encoder LR: {CONFIG['learning_rate_encoder']}")
    print(f"   Classifier LR: {CONFIG['learning_rate_classifier']}")
    print(f"   ì´ í•™ìŠµ ìŠ¤í…: {total_steps:,}")
    print(f"   Warmup ìŠ¤í…: {CONFIG['warmup_steps']}\n")
    
    print("=" * 70)
    print("ğŸš€ í•™ìŠµ ì‹œì‘!")
    print("=" * 70)
    
    best_val_accuracy = 0
    best_epoch = 0
    best_val_report = None  # â­ Best epochì˜ ìƒì„¸ ë¦¬í¬íŠ¸ ì €ì¥
    history = {
        'train_loss': [],
        'val_loss': [],
        'val_accuracy': [],
        'val_f1': [],
        'epoch_time': [],
        'eval_time': []
    }
    
    training_start_time = time.time()
    
    for epoch in range(CONFIG['epochs']):
        print(f"\n{'='*70}")
        print(f"ğŸ“… Epoch {epoch + 1}/{CONFIG['epochs']}")
        print(f"{'='*70}")
        
        epoch_start_time = time.time()
        
        # Training
        model.train()
        total_train_loss = 0
        
        progress_bar = tqdm(train_loader, desc=f"Training Epoch {epoch+1}")
        for batch in progress_bar:
            optimizer.zero_grad()
            
            input_ids = batch['input_ids'].to(device)
            attention_mask = batch['attention_mask'].to(device)
            labels = batch['labels'].to(device)
            
            outputs = model(
                input_ids=input_ids,
                attention_mask=attention_mask,
                labels=labels
            )
            
            loss = outputs.loss
            total_train_loss += loss.item()
            
            loss.backward()
            torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)
            optimizer.step()
            scheduler.step()
            
            progress_bar.set_postfix({
                'loss': f'{loss.item():.4f}',
                'lr': f'{scheduler.get_last_lr()[0]:.2e}'
            })
        
        avg_train_loss = total_train_loss / len(train_loader)
        epoch_time = time.time() - epoch_start_time
        
        # Validation
        print("\nğŸ” Validation ì‹œì‘...")
        val_loss, val_accuracy, val_report, _, _, eval_time = evaluate(
            model, val_loader, device, id2label
        )
        
        # F1 Score (macro average)
        val_f1 = val_report['macro avg']['f1-score']
        
        # ê²°ê³¼ ì €ì¥
        history['train_loss'].append(avg_train_loss)
        history['val_loss'].append(val_loss)
        history['val_accuracy'].append(val_accuracy)
        history['val_f1'].append(val_f1)
        history['epoch_time'].append(epoch_time)
        history['eval_time'].append(eval_time)
        
        # ê²°ê³¼ ì¶œë ¥
        print(f"\n{'='*70}")
        print(f"ğŸ“Š Epoch {epoch + 1} ê²°ê³¼:")
        print(f"{'='*70}")
        print(f"  Train Loss    : {avg_train_loss:.4f}")
        print(f"  Val Loss      : {val_loss:.4f}")
        print(f"  Val Accuracy  : {val_accuracy:.4f} ({val_accuracy*100:.2f}%)")
        print(f"  Val F1 (macro): {val_f1:.4f}")
        print(f"  â±ï¸  Epoch ì‹œê°„   : {epoch_time//60:.0f}ë¶„ {epoch_time%60:.0f}ì´ˆ")
        print(f"  â±ï¸  í‰ê°€ ì‹œê°„    : {eval_time:.1f}ì´ˆ")
        print(f"{'='*70}")
        
        # ê°ì •ë³„ ì„±ëŠ¥
        print("\nğŸ“ˆ ê°ì •ë³„ ì„±ëŠ¥:")
        for label_name in CONFIG['labels']:
            if label_name in val_report:
                metrics = val_report[label_name]
                print(f"  {label_name:12s}: "
                      f"Precision={metrics['precision']:.3f}, "
                      f"Recall={metrics['recall']:.3f}, "
                      f"F1={metrics['f1-score']:.3f}")
        
        # Best model ì €ì¥
        if val_accuracy > best_val_accuracy:
            best_val_accuracy = val_accuracy
            best_epoch = epoch + 1
            best_val_report = val_report  # â­ Best ë¦¬í¬íŠ¸ ì €ì¥
            output_dir = Path(CONFIG['output_dir'])
            output_dir.mkdir(parents=True, exist_ok=True)
            
            print(f"\nğŸ’¾ Best ëª¨ë¸ ì €ì¥ ì¤‘...")
            model.save_pretrained(output_dir)
            tokenizer.save_pretrained(output_dir)
            
            # Config ì €ì¥
            config_save = {k: str(v) if isinstance(v, Path) else v for k, v in CONFIG.items()}
            config_save['best_val_accuracy'] = float(best_val_accuracy)
            config_save['best_val_f1'] = float(val_f1)
            config_save['best_epoch'] = best_epoch
            config_save['trained_at'] = datetime.now().strftime("%Y-%m-%d %H:%M:%S")
            config_save['label2id'] = label2id
            config_save['id2label'] = id2label
            
            with open(output_dir / 'training_config.json', 'w', encoding='utf-8') as f:
                json.dump(config_save, f, indent=2, ensure_ascii=False)
            
            print(f"âœ… Best model ì €ì¥ ì™„ë£Œ!")
            print(f"   Accuracy: {val_accuracy:.4f} ({val_accuracy*100:.2f}%)")
            print(f"   F1 Score: {val_f1:.4f}")
    
    # ì „ì²´ í•™ìŠµ ì‹œê°„
    total_training_time = time.time() - training_start_time
    total_time = time.time() - total_start_time
    
    # â­ Per-class F1 ì¶”ì¶œ (Best epoch)
    per_class_f1 = {}
    per_class_precision = {}
    per_class_recall = {}
    for label_name in CONFIG['labels']:
        if label_name in best_val_report:
            per_class_f1[label_name] = float(best_val_report[label_name]['f1-score'])
            per_class_precision[label_name] = float(best_val_report[label_name]['precision'])
            per_class_recall[label_name] = float(best_val_report[label_name]['recall'])
    
    # í•™ìŠµ ì™„ë£Œ
    print("\n" + "="*70)
    print("ğŸ‰ í•™ìŠµ ì™„ë£Œ!")
    print("="*70)
    print(f"âœ¨ Best Validation Accuracy: {best_val_accuracy:.4f} ({best_val_accuracy*100:.2f}%)")
    print(f"âœ¨ Best Macro F1 Score: {history['val_f1'][best_epoch-1]:.4f}")
    print(f"âœ¨ Best Epoch: {best_epoch}")
    print(f"â±ï¸  ì´ í•™ìŠµ ì‹œê°„: {total_training_time//60:.0f}ë¶„ {total_training_time%60:.0f}ì´ˆ")
    print(f"â±ï¸  ì „ì²´ ì‹¤í–‰ ì‹œê°„: {total_time//60:.0f}ë¶„ {total_time%60:.0f}ì´ˆ")
    print(f"â±ï¸  Epochë‹¹ í‰ê· : {total_training_time/CONFIG['epochs']//60:.0f}ë¶„ {total_training_time/CONFIG['epochs']%60:.0f}ì´ˆ")
    print(f"ğŸ“ ëª¨ë¸ ì €ì¥ ìœ„ì¹˜: {CONFIG['output_dir']}")
    print("="*70 + "\n")
    
    # History ì €ì¥
    history_df = pd.DataFrame(history)
    history_df.to_csv(Path(CONFIG['output_dir']) / 'training_history.csv', index=False)
    print("âœ… í•™ìŠµ íˆìŠ¤í† ë¦¬ ì €ì¥ ì™„ë£Œ: training_history.csv\n")
    
    # â­ ì‹¤í—˜ ê²°ê³¼ ìš”ì•½ ì €ì¥ (Per-class F1 í¬í•¨)
    summary = {
        'experiment_id': CONFIG['experiment_id'],
        'hyperparameters': {
            'epochs': CONFIG['epochs'],
            'batch_size': CONFIG['batch_size'],
            'learning_rate_encoder': CONFIG['learning_rate_encoder'],
            'learning_rate_classifier': CONFIG['learning_rate_classifier'],
        },
        'results': {
            'best_accuracy': float(best_val_accuracy),
            'best_macro_f1': float(history['val_f1'][best_epoch-1]),
            'best_epoch': best_epoch,
            'final_train_loss': float(history['train_loss'][-1]),
            'final_val_loss': float(history['val_loss'][-1]),
            'per_class_f1': per_class_f1,  # â­ ì¶”ê°€
            'per_class_precision': per_class_precision,  # â­ ì¶”ê°€
            'per_class_recall': per_class_recall,  # â­ ì¶”ê°€
        },
        'timing': {
            'total_training_time_seconds': float(total_training_time),
            'total_time_seconds': float(total_time),
            'avg_epoch_time_seconds': float(total_training_time / CONFIG['epochs']),
            'avg_eval_time_seconds': float(np.mean(history['eval_time'])),
        }
    }
    
    with open(Path(CONFIG['output_dir']) / f'{CONFIG["experiment_id"]}_summary.json', 'w', encoding='utf-8') as f:
        json.dump(summary, f, indent=2, ensure_ascii=False)
    
    print(f"âœ… ì‹¤í—˜ ìš”ì•½ ì €ì¥ ì™„ë£Œ: {CONFIG['experiment_id']}_summary.json\n")
    
    # â­ ì½˜ì†”ì— ë³µì‚¬ ê°€ëŠ¥í•œ ê²°ê³¼ ì¶œë ¥ (í™•ì¥ë¨)
    print("\n" + "="*70)
    print("ğŸ“‹ ì‹¤í—˜ ê²°ê³¼ ìš”ì•½ (ë³µì‚¬ìš©)")
    print("="*70)
    print(f"\nğŸ”¬ ì‹¤í—˜ ID: {CONFIG['experiment_id']}")
    print(f"\nğŸ“Š í•˜ì´í¼íŒŒë¼ë¯¸í„°:")
    print(f"  - Epoch: {CONFIG['epochs']}")
    print(f"  - Batch Size: {CONFIG['batch_size']}")
    print(f"  - Learning Rate (Encoder): {CONFIG['learning_rate_encoder']}")
    print(f"  - Learning Rate (Classifier): {CONFIG['learning_rate_classifier']}")
    
    print(f"\nğŸ¯ ì „ì²´ ì„±ëŠ¥ (Best Epoch {best_epoch}):")
    print(f"  - Accuracy: {best_val_accuracy*100:.2f}%")
    print(f"  - Macro F1 Score: {history['val_f1'][best_epoch-1]:.4f}")
    print(f"  - Train Loss: {history['train_loss'][best_epoch-1]:.4f}")
    print(f"  - Val Loss: {history['val_loss'][best_epoch-1]:.4f}")
    
    print(f"\nğŸ“ˆ ê°ì •ë³„ F1 Score (Per-class):")
    print(f"  â”Œ{'â”€'*14}â”¬{'â”€'*12}â”¬{'â”€'*12}â”¬{'â”€'*12}â”")
    print(f"  â”‚ {'Emotion':12s} â”‚ {'Precision':>10s} â”‚ {'Recall':>10s} â”‚ {'F1-Score':>10s} â”‚")
    print(f"  â”œ{'â”€'*14}â”¼{'â”€'*12}â”¼{'â”€'*12}â”¼{'â”€'*12}â”¤")
    for label_name in CONFIG['labels']:
        if label_name in per_class_f1:
            prec = per_class_precision[label_name]
            rec = per_class_recall[label_name]
            f1 = per_class_f1[label_name]
            print(f"  â”‚ {label_name:12s} â”‚ {prec:10.3f} â”‚ {rec:10.3f} â”‚ {f1:10.3f} â”‚")
    print(f"  â””{'â”€'*14}â”´{'â”€'*12}â”´{'â”€'*12}â”´{'â”€'*12}â”˜")
    
    print(f"\nâ±ï¸  í•™ìŠµ ì‹œê°„:")
    print(f"  - ì´ í•™ìŠµ ì‹œê°„: {total_training_time//60:.0f}ë¶„ {total_training_time%60:.0f}ì´ˆ")
    print(f"  - Epochë‹¹ í‰ê· : {total_training_time/CONFIG['epochs']//60:.0f}ë¶„ {total_training_time/CONFIG['epochs']%60:.0f}ì´ˆ")
    print(f"  - í‰ê°€ ì‹œê°„: {np.mean(history['eval_time']):.1f}ì´ˆ")
    
    print("="*70)
    
    return model, history

# ============================================================
# ë©”ì¸ ì‹¤í–‰
# ============================================================
if __name__ == "__main__":
    try:
        model, history = train()
        print("âœ… ëª¨ë“  ì‘ì—… ì™„ë£Œ!")
    except Exception as e:
        print(f"\nâŒ ì˜¤ë¥˜ ë°œìƒ: {e}")
        import traceback
        traceback.print_exc()